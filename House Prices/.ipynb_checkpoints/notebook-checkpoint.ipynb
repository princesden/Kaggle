{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out a linear model: \n",
    "\n",
    "Author: Alexandru Papiu    \n",
    "If you use parts of this notebook in your own scripts, please give some sort of credit (for example link back to this). Thanks!\n",
    "\n",
    "\n",
    "There have been a few [great](https://www.kaggle.com/comartel/house-prices-advanced-regression-techniques/house-price-xgboost-starter/run/348739)  [scripts](https://www.kaggle.com/zoupet/house-prices-advanced-regression-techniques/xgboost-10-kfolds-with-scikit-learn/run/357561) on [xgboost](https://www.kaggle.com/tadepalli/house-prices-advanced-regression-techniques/xgboost-with-n-trees-autostop-0-12638/run/353049) already so I'd figured I'd try something simpler: a regularized linear regression model. Surprisingly it does really well with very little feature engineering. The key point is to to log_transform the numeric variables since most of them are skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/Princewill/OneDrive/Datasets/House Price/input/train.csv\")\n",
    "test = pd.read_csv(\"/Users/Princewill/OneDrive/Datasets/House Price/input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RcParams({'_internal.classic_mode': False,\n",
       "          'agg.path.chunksize': 0,\n",
       "          'animation.avconv_args': [],\n",
       "          'animation.avconv_path': 'avconv',\n",
       "          'animation.bitrate': -1,\n",
       "          'animation.codec': 'h264',\n",
       "          'animation.convert_args': [],\n",
       "          'animation.convert_path': 'convert',\n",
       "          'animation.ffmpeg_args': [],\n",
       "          'animation.ffmpeg_path': 'ffmpeg',\n",
       "          'animation.frame_format': 'png',\n",
       "          'animation.html': 'none',\n",
       "          'animation.mencoder_args': [],\n",
       "          'animation.mencoder_path': 'mencoder',\n",
       "          'animation.writer': 'ffmpeg',\n",
       "          'axes.autolimit_mode': 'data',\n",
       "          'axes.axisbelow': True,\n",
       "          'axes.edgecolor': 'white',\n",
       "          'axes.facecolor': '#EAEAF2',\n",
       "          'axes.formatter.limits': [-7, 7],\n",
       "          'axes.formatter.offset_threshold': 4,\n",
       "          'axes.formatter.use_locale': False,\n",
       "          'axes.formatter.use_mathtext': False,\n",
       "          'axes.formatter.useoffset': True,\n",
       "          'axes.grid': True,\n",
       "          'axes.grid.axis': 'both',\n",
       "          'axes.grid.which': 'major',\n",
       "          'axes.hold': None,\n",
       "          'axes.labelcolor': '.15',\n",
       "          'axes.labelpad': 4.0,\n",
       "          'axes.labelsize': 11.0,\n",
       "          'axes.labelweight': 'normal',\n",
       "          'axes.linewidth': 0.0,\n",
       "          'axes.prop_cycle': cycler('color', [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.3333333333333333, 0.6588235294117647, 0.40784313725490196), (0.7686274509803922, 0.3058823529411765, 0.3215686274509804), (0.5058823529411764, 0.4470588235294118, 0.6980392156862745), (0.8, 0.7254901960784313, 0.4549019607843137), (0.39215686274509803, 0.7098039215686275, 0.803921568627451)]),\n",
       "          'axes.spines.bottom': True,\n",
       "          'axes.spines.left': True,\n",
       "          'axes.spines.right': True,\n",
       "          'axes.spines.top': True,\n",
       "          'axes.titlepad': 6.0,\n",
       "          'axes.titlesize': 12.0,\n",
       "          'axes.titleweight': 'normal',\n",
       "          'axes.unicode_minus': True,\n",
       "          'axes.xmargin': 0.05,\n",
       "          'axes.ymargin': 0.05,\n",
       "          'axes3d.grid': True,\n",
       "          'backend': 'module://ipykernel.pylab.backend_inline',\n",
       "          'backend.qt4': 'PyQt4',\n",
       "          'backend.qt5': 'PyQt5',\n",
       "          'backend_fallback': True,\n",
       "          'boxplot.bootstrap': None,\n",
       "          'boxplot.boxprops.color': 'k',\n",
       "          'boxplot.boxprops.linestyle': '-',\n",
       "          'boxplot.boxprops.linewidth': 1.0,\n",
       "          'boxplot.capprops.color': 'k',\n",
       "          'boxplot.capprops.linestyle': '-',\n",
       "          'boxplot.capprops.linewidth': 1.0,\n",
       "          'boxplot.flierprops.color': 'k',\n",
       "          'boxplot.flierprops.linestyle': 'none',\n",
       "          'boxplot.flierprops.linewidth': 1.0,\n",
       "          'boxplot.flierprops.marker': 'o',\n",
       "          'boxplot.flierprops.markeredgecolor': 'k',\n",
       "          'boxplot.flierprops.markerfacecolor': 'none',\n",
       "          'boxplot.flierprops.markersize': 6.0,\n",
       "          'boxplot.meanline': False,\n",
       "          'boxplot.meanprops.color': 'C2',\n",
       "          'boxplot.meanprops.linestyle': '--',\n",
       "          'boxplot.meanprops.linewidth': 1.0,\n",
       "          'boxplot.meanprops.marker': '^',\n",
       "          'boxplot.meanprops.markeredgecolor': 'C2',\n",
       "          'boxplot.meanprops.markerfacecolor': 'C2',\n",
       "          'boxplot.meanprops.markersize': 6.0,\n",
       "          'boxplot.medianprops.color': 'C1',\n",
       "          'boxplot.medianprops.linestyle': '-',\n",
       "          'boxplot.medianprops.linewidth': 1.0,\n",
       "          'boxplot.notch': False,\n",
       "          'boxplot.patchartist': False,\n",
       "          'boxplot.showbox': True,\n",
       "          'boxplot.showcaps': True,\n",
       "          'boxplot.showfliers': True,\n",
       "          'boxplot.showmeans': False,\n",
       "          'boxplot.vertical': True,\n",
       "          'boxplot.whiskerprops.color': 'k',\n",
       "          'boxplot.whiskerprops.linestyle': '-',\n",
       "          'boxplot.whiskerprops.linewidth': 1.0,\n",
       "          'boxplot.whiskers': 1.5,\n",
       "          'contour.corner_mask': True,\n",
       "          'contour.negative_linestyle': 'dashed',\n",
       "          'datapath': '/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/matplotlib/mpl-data',\n",
       "          'date.autoformatter.day': '%Y-%m-%d',\n",
       "          'date.autoformatter.hour': '%m-%d %H',\n",
       "          'date.autoformatter.microsecond': '%M:%S.%f',\n",
       "          'date.autoformatter.minute': '%d %H:%M',\n",
       "          'date.autoformatter.month': '%Y-%m',\n",
       "          'date.autoformatter.second': '%H:%M:%S',\n",
       "          'date.autoformatter.year': '%Y',\n",
       "          'docstring.hardcopy': False,\n",
       "          'errorbar.capsize': 0.0,\n",
       "          'examples.directory': '',\n",
       "          'figure.autolayout': False,\n",
       "          'figure.dpi': 72.0,\n",
       "          'figure.edgecolor': (1, 1, 1, 0),\n",
       "          'figure.facecolor': (1, 1, 1, 0),\n",
       "          'figure.figsize': [6.0, 4.0],\n",
       "          'figure.frameon': True,\n",
       "          'figure.max_open_warning': 20,\n",
       "          'figure.subplot.bottom': 0.125,\n",
       "          'figure.subplot.hspace': 0.2,\n",
       "          'figure.subplot.left': 0.125,\n",
       "          'figure.subplot.right': 0.9,\n",
       "          'figure.subplot.top': 0.88,\n",
       "          'figure.subplot.wspace': 0.2,\n",
       "          'figure.titlesize': 'large',\n",
       "          'figure.titleweight': 'normal',\n",
       "          'font.cursive': ['Apple Chancery',\n",
       "                           'Textile',\n",
       "                           'Zapf Chancery',\n",
       "                           'Sand',\n",
       "                           'Script MT',\n",
       "                           'Felipa',\n",
       "                           'cursive'],\n",
       "          'font.family': ['sans-serif'],\n",
       "          'font.fantasy': ['Comic Sans MS',\n",
       "                           'Chicago',\n",
       "                           'Charcoal',\n",
       "                           'ImpactWestern',\n",
       "                           'Humor Sans',\n",
       "                           'xkcd',\n",
       "                           'fantasy'],\n",
       "          'font.monospace': ['DejaVu Sans Mono',\n",
       "                             'Bitstream Vera Sans Mono',\n",
       "                             'Computer Modern Typewriter',\n",
       "                             'Andale Mono',\n",
       "                             'Nimbus Mono L',\n",
       "                             'Courier New',\n",
       "                             'Courier',\n",
       "                             'Fixed',\n",
       "                             'Terminal',\n",
       "                             'monospace'],\n",
       "          'font.sans-serif': ['Arial',\n",
       "                              'Liberation Sans',\n",
       "                              'Bitstream Vera Sans',\n",
       "                              'sans-serif'],\n",
       "          'font.serif': ['DejaVu Serif',\n",
       "                         'Bitstream Vera Serif',\n",
       "                         'Computer Modern Roman',\n",
       "                         'New Century Schoolbook',\n",
       "                         'Century Schoolbook L',\n",
       "                         'Utopia',\n",
       "                         'ITC Bookman',\n",
       "                         'Bookman',\n",
       "                         'Nimbus Roman No9 L',\n",
       "                         'Times New Roman',\n",
       "                         'Times',\n",
       "                         'Palatino',\n",
       "                         'Charter',\n",
       "                         'serif'],\n",
       "          'font.size': 10.0,\n",
       "          'font.stretch': 'normal',\n",
       "          'font.style': 'normal',\n",
       "          'font.variant': 'normal',\n",
       "          'font.weight': 'normal',\n",
       "          'grid.alpha': 1.0,\n",
       "          'grid.color': 'white',\n",
       "          'grid.linestyle': '-',\n",
       "          'grid.linewidth': 1.0,\n",
       "          'hatch.color': 'k',\n",
       "          'hatch.linewidth': 1.0,\n",
       "          'hist.bins': 10,\n",
       "          'image.aspect': 'equal',\n",
       "          'image.cmap': 'Greys',\n",
       "          'image.composite_image': True,\n",
       "          'image.interpolation': 'nearest',\n",
       "          'image.lut': 256,\n",
       "          'image.origin': 'upper',\n",
       "          'image.resample': True,\n",
       "          'interactive': True,\n",
       "          'keymap.all_axes': ['a'],\n",
       "          'keymap.back': ['left', 'c', 'backspace'],\n",
       "          'keymap.forward': ['right', 'v'],\n",
       "          'keymap.fullscreen': ['f', 'ctrl+f'],\n",
       "          'keymap.grid': ['g'],\n",
       "          'keymap.home': ['h', 'r', 'home'],\n",
       "          'keymap.pan': ['p'],\n",
       "          'keymap.quit': ['ctrl+w', 'cmd+w'],\n",
       "          'keymap.save': ['s', 'ctrl+s'],\n",
       "          'keymap.xscale': ['k', 'L'],\n",
       "          'keymap.yscale': ['l'],\n",
       "          'keymap.zoom': ['o'],\n",
       "          'legend.borderaxespad': 0.5,\n",
       "          'legend.borderpad': 0.4,\n",
       "          'legend.columnspacing': 2.0,\n",
       "          'legend.edgecolor': '0.8',\n",
       "          'legend.facecolor': 'inherit',\n",
       "          'legend.fancybox': True,\n",
       "          'legend.fontsize': 10.0,\n",
       "          'legend.framealpha': 0.8,\n",
       "          'legend.frameon': False,\n",
       "          'legend.handleheight': 0.7,\n",
       "          'legend.handlelength': 2.0,\n",
       "          'legend.handletextpad': 0.8,\n",
       "          'legend.labelspacing': 0.5,\n",
       "          'legend.loc': 'best',\n",
       "          'legend.markerscale': 1.0,\n",
       "          'legend.numpoints': 1,\n",
       "          'legend.scatterpoints': 1,\n",
       "          'legend.shadow': False,\n",
       "          'lines.antialiased': True,\n",
       "          'lines.color': 'C0',\n",
       "          'lines.dash_capstyle': 'butt',\n",
       "          'lines.dash_joinstyle': 'round',\n",
       "          'lines.dashdot_pattern': [4.8, 1.2, 0.8, 1.2],\n",
       "          'lines.dashed_pattern': [2.8, 1.2],\n",
       "          'lines.dotted_pattern': [1.1, 1.1],\n",
       "          'lines.linestyle': '-',\n",
       "          'lines.linewidth': 1.75,\n",
       "          'lines.marker': 'None',\n",
       "          'lines.markeredgewidth': 0.0,\n",
       "          'lines.markersize': 7.0,\n",
       "          'lines.scale_dashes': True,\n",
       "          'lines.solid_capstyle': 'round',\n",
       "          'lines.solid_joinstyle': 'round',\n",
       "          'markers.fillstyle': 'full',\n",
       "          'mathtext.bf': 'sans:bold',\n",
       "          'mathtext.cal': 'cursive',\n",
       "          'mathtext.default': 'it',\n",
       "          'mathtext.fallback_to_cm': True,\n",
       "          'mathtext.fontset': 'dejavusans',\n",
       "          'mathtext.it': 'sans:italic',\n",
       "          'mathtext.rm': 'sans',\n",
       "          'mathtext.sf': 'sans',\n",
       "          'mathtext.tt': 'monospace',\n",
       "          'nbagg.transparent': True,\n",
       "          'patch.antialiased': True,\n",
       "          'patch.edgecolor': 'k',\n",
       "          'patch.facecolor': (0.2980392156862745,\n",
       "                              0.4470588235294118,\n",
       "                              0.6901960784313725),\n",
       "          'patch.force_edgecolor': False,\n",
       "          'patch.linewidth': 0.3,\n",
       "          'path.effects': [],\n",
       "          'path.simplify': True,\n",
       "          'path.simplify_threshold': 0.1111111111111111,\n",
       "          'path.sketch': None,\n",
       "          'path.snap': True,\n",
       "          'pdf.compression': 6,\n",
       "          'pdf.fonttype': 3,\n",
       "          'pdf.inheritcolor': False,\n",
       "          'pdf.use14corefonts': False,\n",
       "          'pgf.debug': False,\n",
       "          'pgf.preamble': [],\n",
       "          'pgf.rcfonts': True,\n",
       "          'pgf.texsystem': 'xelatex',\n",
       "          'plugins.directory': '.matplotlib_plugins',\n",
       "          'polaraxes.grid': True,\n",
       "          'ps.distiller.res': 6000,\n",
       "          'ps.fonttype': 3,\n",
       "          'ps.papersize': 'letter',\n",
       "          'ps.useafm': False,\n",
       "          'ps.usedistiller': False,\n",
       "          'savefig.bbox': None,\n",
       "          'savefig.directory': '~',\n",
       "          'savefig.dpi': 'figure',\n",
       "          'savefig.edgecolor': 'w',\n",
       "          'savefig.facecolor': 'w',\n",
       "          'savefig.format': 'png',\n",
       "          'savefig.frameon': True,\n",
       "          'savefig.jpeg_quality': 95,\n",
       "          'savefig.orientation': 'portrait',\n",
       "          'savefig.pad_inches': 0.1,\n",
       "          'savefig.transparent': False,\n",
       "          'scatter.marker': 'o',\n",
       "          'svg.fonttype': 'path',\n",
       "          'svg.hashsalt': None,\n",
       "          'svg.image_inline': True,\n",
       "          'text.antialiased': True,\n",
       "          'text.color': '.15',\n",
       "          'text.dvipnghack': None,\n",
       "          'text.hinting': 'auto',\n",
       "          'text.hinting_factor': 8,\n",
       "          'text.latex.preamble': [],\n",
       "          'text.latex.preview': False,\n",
       "          'text.latex.unicode': False,\n",
       "          'text.usetex': False,\n",
       "          'timezone': 'UTC',\n",
       "          'tk.window_focus': False,\n",
       "          'toolbar': 'toolbar2',\n",
       "          'verbose.fileo': 'sys.stdout',\n",
       "          'verbose.level': 'silent',\n",
       "          'webagg.open_in_browser': True,\n",
       "          'webagg.port': 8988,\n",
       "          'webagg.port_retries': 50,\n",
       "          'xtick.bottom': True,\n",
       "          'xtick.color': '.15',\n",
       "          'xtick.direction': 'out',\n",
       "          'xtick.labelsize': 10.0,\n",
       "          'xtick.major.bottom': True,\n",
       "          'xtick.major.pad': 7.0,\n",
       "          'xtick.major.size': 0.0,\n",
       "          'xtick.major.top': True,\n",
       "          'xtick.major.width': 1.0,\n",
       "          'xtick.minor.bottom': True,\n",
       "          'xtick.minor.pad': 3.4,\n",
       "          'xtick.minor.size': 0.0,\n",
       "          'xtick.minor.top': True,\n",
       "          'xtick.minor.visible': False,\n",
       "          'xtick.minor.width': 0.5,\n",
       "          'xtick.top': False,\n",
       "          'ytick.color': '.15',\n",
       "          'ytick.direction': 'out',\n",
       "          'ytick.labelsize': 10.0,\n",
       "          'ytick.left': True,\n",
       "          'ytick.major.left': True,\n",
       "          'ytick.major.pad': 7.0,\n",
       "          'ytick.major.right': True,\n",
       "          'ytick.major.size': 0.0,\n",
       "          'ytick.major.width': 1.0,\n",
       "          'ytick.minor.left': True,\n",
       "          'ytick.minor.pad': 3.4,\n",
       "          'ytick.minor.right': True,\n",
       "          'ytick.minor.size': 0.0,\n",
       "          'ytick.minor.visible': False,\n",
       "          'ytick.minor.width': 0.5,\n",
       "          'ytick.right': False})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.rcParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data preprocessing: \n",
    "We're not going to do anything fancy here: \n",
    " \n",
    "- First I'll transform the skewed numeric features by taking log(feature + 1) - this will make the features more normal    \n",
    "- Create Dummy variables for the categorical features    \n",
    "- Replace the numeric missing values (NaN's) with the mean of their respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x109573cf8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x109750b00>]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYcAAALoCAYAAAAjjUruAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1042e8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "prices = pd.DataFrame({\"price\":train[\"SalePrice\"], \"log(price + 1)\":np.log1p(train[\"SalePrice\"])})\n",
    "prices.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#log transform the target:\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "\n",
    "#log transform skewed numeric features:\n",
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "skewed_feats = skewed_feats.index\n",
    "\n",
    "all_data[skewed_feats] = np.log1p(all_data[skewed_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filling NA's with the mean of the column:\n",
    "all_data = all_data.fillna(all_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating matrices for sklearn:\n",
    "X_train = all_data[:train.shape[0]]\n",
    "X_test = all_data[train.shape[0]:]\n",
    "y = train.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Models\n",
    "\n",
    "Now we are going to use regularized linear regression models from the scikit learn module. I'm going to try both l_1(Lasso) and l_2(Ridge) regularization. I'll also define a function that returns the cross-validation rmse error so we can evaluate our models and pick the best tuning par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ridge = Ridge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main tuning parameter for the Ridge model is alpha - a regularization parameter that measures how flexible our model is. The higher the regularization the less prone our model will be to overfit. However it will also lose flexibility and might not capture all of the signal in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f0155afd1db9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n\u001b[0;32m----> 3\u001b[0;31m             for alpha in alphas]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-f0155afd1db9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n\u001b[0;32m----> 3\u001b[0;31m             for alpha in alphas]\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-3f33c98ee18e>\u001b[0m in \u001b[0;36mrmse_cv\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrmse_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mrmse\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_mean_squared_error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \"\"\"\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         X, y = check_X_y(X, y, ['csr', 'csc', 'coo'], dtype=np.float64,\n\u001b[0;32m--> 465\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Normal'"
     ]
    }
   ],
   "source": [
    "alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\n",
    "cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n",
    "            for alpha in alphas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_ridge = pd.Series(cv_ridge, index = alphas)\n",
    "cv_ridge.plot(title = \"Validation - Just Do It\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the U-ish shaped curve above. When alpha is too large the regularization is too strong and the model cannot capture all the complexities in the data. If however we let the model be too flexible (alpha small) the model begins to overfit. A value of alpha = 10 is about right based on the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_ridge.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for the Ridge regression we get a rmsle of about 0.127\n",
    "\n",
    "Let' try out the Lasso model. We will do a slightly different approach here and use the built in Lasso CV to figure out the best alpha for us. For some reason the alphas in Lasso CV are really the inverse or the alphas in Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse_cv(model_lasso).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! The lasso performs even better so we'll just use this one to predict on the test set. Another neat thing about the Lasso is that it does feature selection for you - setting coefficients of features it deems unimportant to zero. Let's take a look at the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job Lasso.  One thing to note here however is that the features selected are not necessarily the \"correct\" ones - especially since there are a lot of collinear features in this dataset. One idea to try here is run Lasso a few times on boostrapped samples and see how stable the feature selection is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look directly at what the most important coefficients are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important positive feature is `GrLivArea` -  the above ground area by area square feet. This definitely sense. Then a few other  location and quality features contributed positively. Some of the negative features make less sense and would be worth looking into more - it seems like they might come from unbalanced categorical variables.\n",
    "\n",
    " Also note that unlike the feature importance you'd get from a random forest these are _actual_ coefficients in your model - so you can say precisely why the predicted price is what it is. The only issue here is that we log_transformed both the target and the numeric features so the actual magnitudes are a bit hard to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's look at the residuals as well:\n",
    "matplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n",
    "\n",
    "preds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\n",
    "preds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\n",
    "preds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual plot looks pretty good.To wrap it up let's predict on the test set and submit on the leaderboard:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an xgboost model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an xgboost model to our linear model to see if we can improve our score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label = y)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\"max_depth\":2, \"eta\":0.1}\n",
    "model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\n",
    "model_xgb.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_preds = np.expm1(model_xgb.predict(X_test))\n",
    "lasso_preds = np.expm1(model_lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\n",
    "predictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times it makes sense to take a weighted average of uncorrelated results - this usually imporoves the score although in this case it doesn't help that much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = 0.7*lasso_preds + 0.3*xgb_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solution = pd.DataFrame({\"id\":test.Id, \"SalePrice\":preds})\n",
    "solution.to_csv(\"ridge_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out keras?\n",
    "\n",
    "Feedforward Neural Nets doesn't seem to work well at all...I wonder why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Dense(256, activation=\"relu\", input_dim = X_train.shape[1]))\n",
    "model.add(Dense(1, input_dim = X_train.shape[1], W_regularizer=l1(0.001)))\n",
    "\n",
    "model.compile(loss = \"mse\", optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(X_tr, y_tr, validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(model.predict(X_val)[:,0]).hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
